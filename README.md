## Here is my task 

### Web scraping 
Scraping review data from the web via the Skytrax website is the first step. The focus is on collecting data on reviews specifically about the airline itself. After data collection, I need to prepare the dataset by performing data cleaning. As the data will be messy and contain text only, I should conduct my own analysis, such as topic modelling, sentiment analysis, or wordclouds to provide insights into the reviews. Completing the task using Python is recommended, although any tool can be used. Documentation websites provided in the Resources section below can be used for data analysis. Check in ``` Scraping data.ipynb  ``` .

### Explore and prepare the dataset (Exploratory Data Analysis-EDA)
First, spend some time exploring the dataset in the Jupyter Notebook provided in the Resources section below to understand the different columns and some basic statistics of the dataset. Then, I focused to consider how to prepare the dataset for a predictive model. I also thinked about any new features you want to create in order to make your model even better. I did make use of the Resources provided to get you started with this task. 

### Train a machine learning model
When my data is ready for modelling, I trained a machine learning model to be able to predict the target outcome, which is a customer making a booking. For this task, I used some algorithms that easily allows you to output information about how each variable within the model contributes to its predictive power. For example,I found that with imbalance dataset some algorithms such as RandomForest, XGBoost are very good for this purpose. I pre-processed data and built model in file ``` Modelling_EDA_2.ipynb ```.

### Evaluate model and present findings
After training my model, I did evaluate how well it performed by conducting cross-validation and outputting appropriate evaluation metrics. Furthermore, I created a visualisation to interpret how each variable contributed to the model. Finally, I summarised your findings in a single slide. Click the ``` task 2 - updated.pdf ``` provided in the Resources section below to check my summary and make use of the links provided to help with this task.

### Optional task
I also tried to exploratory data analysis from NLP project with dataset that I did crawl before. I focused on cleaning this dataset and then I turned to immerse deeper into this datasets to get insight of its. This dataset isn't available in github now, so if you want to check there is feasible file  ``` Data Analysis.ipynb``` to see briefly.